# MIP-260221: Structured Projection & Multi-Dimensional Indexing
**Date**: 2026-02-21 AEDT
**Author**: Master Brian (compiled with Antigravity analysis)
**Contributions**: Lilac Metaflora ([MIP-260221-SUPPLEMENT](./MIP260221_lilac.md))
**Triggered by**: [moon_recall_failure_report_0539.md](/MOON/moon_recall_failure_report_0539.md)
**Status**: Draft — Under Review

---

## 1. Problem Statement

MOON's current JSONL → MD projection pipeline (`archives/raw/*.md`) performs aggressive de-noising that strips too much — timestamps, tool call metadata, message structure — and outputs a flat bullet list under a single `## Signals` heading. This causes:

1. **Timestamp blindness** — No local-time or UTC timestamp is preserved per message. Queries like "what happened at 05:39 AEDT" fail because the projection contains no temporal anchors.
2. **No semantic structure** — All messages (user, assistant, tool) are flattened into a uniform `- [role] text` list. There is no categorisation by topic, tool usage, or conversational phase.
3. **Keyword/meaning loss** — The 280-char truncation and 220-char tool result cap strip contextual keywords. The `is_signal_line` filter only keeps lines containing 5 hardcoded words (`decision`, `rule`, `todo`, `next`, `milestone`), discarding everything else.
4. **Escaped JSON noise** — Deeply nested tool outputs with excessive escaping (`\\\"`) are either kept as-is (confusing embeddings) or rejected entirely (losing signal).

**Net effect**: Lilac cannot reliably retrieve pre-compaction session data via `moon-recall`, especially for time-based, tool-based, or keyword-based queries.

---

## 2. Design Goals

| Goal | Description |
|---|---|
| **G1: Noise-free, full-signal projections** | Strip JSONL structural noise (escape sequences, parent IDs, wire-format fields) but preserve all human-readable content |
| **G2: Multi-dimensional indexing** | Every projection entry should be indexable by timestamp, role, keywords, and semantic meaning |
| **G3: Structured categories** | Group projection content into well-defined sections — not a flat list |
| **G4: Fast retrieval** | Lilac should find any prior conversation, decision, or tool output in ≤ 2 queries |
| **G5: Backward compatibility** | Existing `moon-recall` + QMD pipeline must continue to work; improvements are additive |

---

## 3. Proposed Architecture

### 3.1 New Projection Format (`archives/raw/*.md`)

Replace the current flat `## Signals` format with a structured, multi-section markdown document.

#### Current Format (before)
```md
---
moon_archive_projection: 1
session_id: "abc123"
archive_jsonl_path: "/path/to/archive.jsonl"
content_hash: "sha256..."
created_at_epoch_secs: 1708480000
---

# Archive Projection

This file stores non-noise text signals extracted from the raw session archive for retrieval.

## Signals
- [user] how do I deploy the app
- [assistant] You can deploy using cargo run -- install
- [tool] command exited with code 0
```

#### New Format (after)
```md
---
moon_archive_projection: 2
session_id: "abc123"
archive_jsonl_path: "/path/to/archive.jsonl"
content_hash: "sha256..."
created_at_epoch_secs: 1708480000
time_range_utc: "2026-02-21T18:39:00Z — 2026-02-21T19:15:00Z"
time_range_local: "2026-02-22T05:39:00+11:00 — 2026-02-22T06:15:00+11:00"
local_timezone: "AEDT (+11:00)"
message_count: 42
tool_calls: ["run_command", "read_file", "write_to_file"]
keywords: ["deploy", "cargo", "install", "wrangler", "cloudflare"]
topics: ["deployment", "build configuration"]
---

# Archive Projection — abc123

> Session: 2026-02-22 05:39–06:15 AEDT (2026-02-21 18:39–19:15 UTC)
> Messages: 42 | Tools used: run_command, read_file, write_to_file

## Timeline

| # | Time (UTC) | Time (Local) | Role | Summary |
|---|---|---|---|---|
| 1 | 18:39:12Z | 05:39:12 AEDT | user | "how do I deploy the app to Cloudflare?" |
| 2 | 18:39:15Z | 05:39:15 AEDT | assistant | Explained wrangler setup and cargo build steps |
| 3 | 18:39:30Z | 05:39:30 AEDT | tool:run_command | `cargo build --release` → exit 0 |
| ... | ... | ... | ... | ... |

## Conversations

### User Queries
- [18:39:12Z] "how do I deploy the app to Cloudflare?"
- [18:42:00Z] "what about the environment variables?"

### Assistant Responses
- [18:39:15Z] Explained wrangler setup: need to run `cargo build` first, then `npx wrangler deploy`
- [18:42:05Z] Listed required env vars: `OPENCLAW_BIN`, `QMD_BIN`, `MOON_HOME`

## Tool Activity

### run_command
- [18:39:30Z] `cargo build --release` → exit 0
- [18:41:15Z] `npx wrangler dev` → exit 0 (dev server started on localhost:8787)

### read_file
- [18:40:00Z] Read `wrangler.toml` (234 bytes)

### write_to_file
- [18:40:45Z] Created `.env` with deployment configuration

## Decisions & Outcomes
- Decided to use `wrangler dev` for local testing before deploying to production
- Confirmed environment variables are loaded from `.env` on CLI startup

## Keywords & Topics
- **Keywords**: deploy, cargo, wrangler, cloudflare, environment variables, .env, build
- **Topics**: Deployment pipeline, Build configuration, Environment setup

## Compaction Notes
- Summary injected at message #38 (context exceeded 75k tokens)
- Pre-compaction goal: "Deploy the application to Cloudflare Workers"
```

### 3.2 Changes to the Projection Pipeline

The following code changes implement the new format:

---

#### [MODIFY] [archive.rs](file:///C:/Users/czhu6/gh/MOON/src/moon/archive.rs)

**`render_projection_markdown`** — Replace the current flat-list renderer with a structured renderer that accepts the new `ProjectionData` struct and writes all sections.

**`write_archive_projection`** — Update to pass the full `ProjectionData` from the new excerpt extractor.

**YAML frontmatter** — Bump `moon_archive_projection` version to `2`. Add fields: `time_range_utc`, `time_range_local`, `local_timezone`, `message_count`, `tool_calls`, `keywords`, `topics`.

---

#### [MODIFY] [distill.rs](file:///C:/Users/czhu6/gh/MOON/src/moon/distill.rs)

**`load_archive_excerpt`** → Rename/refactor to **`extract_projection_data`**. Instead of returning a flat `String`, return a new `ProjectionData` struct:

```rust
pub struct ProjectionData {
    /// Per-message entries with timestamp + role + cleaned content
    pub entries: Vec<ProjectionEntry>,
    /// Extracted unique tool names used in the session
    pub tool_calls: Vec<String>,
    /// Auto-extracted keywords (nouns, proper nouns, technical terms)
    pub keywords: Vec<String>,
    /// LLM-inferred or heuristic topic labels
    pub topics: Vec<String>,
    /// Earliest message timestamp (epoch secs)
    pub time_start_epoch: Option<u64>,
    /// Latest message timestamp (epoch secs)
    pub time_end_epoch: Option<u64>,
    /// Total message count
    pub message_count: usize,
    /// Whether the archive was truncated during scan
    pub truncated: bool,
    /// Compaction anchors: summary text mapped to origin message_id (Lilac §1)
    pub compaction_anchors: Vec<CompactionAnchor>,
}

/// Traceable compaction record — links summary text to its source message
pub struct CompactionAnchor {
    /// The compaction summary text
    pub note: String,
    /// The message_id that triggered this compaction event
    pub origin_message_id: Option<String>,
}

/// Side-effect priority for tool calls (Lilac §2)
#[derive(Debug, Clone, PartialEq)]
pub enum ToolPriority {
    /// Write/execute tools: write_to_file, exec, edit, gateway config.patch
    High,
    /// Read-only tools: read_file, web_search, ls
    Normal,
}

pub struct ProjectionEntry {
    /// UTC timestamp of the message (epoch secs)
    pub timestamp_epoch: Option<u64>,
    /// Role: "user", "assistant", "tool:{tool_name}", "system"
    pub role: String,
    /// Cleaned, unescaped, human-readable content
    pub content: String,
    /// Optional tool name (for tool results)
    pub tool_name: Option<String>,
    /// Optional command/path (for tool calls)
    pub tool_target: Option<String>,
    /// Side-effect priority for ranking (Lilac §2)
    pub priority: Option<ToolPriority>,
    /// Coupled tool result (Lilac §3: contextual stitching)
    /// When role is "assistant:toolUse", this holds the paired toolResult content
    pub coupled_result: Option<String>,
}
```

**`push_message_candidates`** → Refactor to **`extract_message_entry`**. Instead of pushing into a flat `Vec<String>`, construct a `ProjectionEntry` with:
- **Timestamp extraction**: Parse `message.createdAt` or the JSONL entry timestamp field
- **Role extraction**: Keep the existing role detection but store as structured field
- **Tool name extraction**: For `toolResult` and `toolUse` entries, extract the tool name (e.g., `run_command`, `read_file`)
- **JSON unescaping**: Apply a recursive JSON unescape pass before cleaning text (fixing the `\\\"` noise issue from the failure report)
- **Relaxed size limits**: Increase tool result limit from 220 → 1024 chars; increase general truncation from 280 → 512 chars

**`clean_candidate_text`** → Add a **JSON unescape pre-pass**:
```rust
fn unescape_json_noise(input: &str) -> String {
    input
        .replace("\\\\\"", "\"")
        .replace("\\\\n", "\n")
        .replace("\\\\t", "\t")
        .replace("\\\\\\\\", "\\")
}
```

**Keyword extraction** — New function `extract_keywords(entries: &[ProjectionEntry]) -> Vec<String>`:
- Collect unique nouns/terms from user and assistant messages
- Filter out stopwords and common fillers
- Keep technical terms (file paths, command names, package names)
- Cap at 30 keywords per projection

**Topic inference** — New function `infer_topics(entries: &[ProjectionEntry], keywords: &[String]) -> Vec<String>`:
- For `local` distiller: Use keyword clustering heuristics (group related keywords into topic labels)
- For remote distillers: Ask the model in the distill prompt to also return 2-5 topic labels

---

#### [MODIFY] [recall.rs](file:///C:/Users/czhu6/gh/MOON/src/moon/recall.rs)

**`snippet_from_archive`** — Update to parse the new v2 projection format. When reading the projection, prefer extracting content from the `## Conversations` or `## Timeline` section instead of just the first non-header line.

**`recall`** — Add **timezone-aware query pre-processing**:
- Detect time patterns in the query (e.g., "05:39 AEDT", "yesterday at 3pm")
- Convert to UTC and add as a parallel lexical search term against `time_range_utc` / `time_range_local` in the YAML frontmatter
- This enables frontmatter-based temporal filtering before vector search

---

#### [MODIFY] [snapshot.rs](file:///C:/Users/czhu6/gh/MOON/src/moon/snapshot.rs)

**`write_snapshot`** — Detect the user's local timezone at snapshot time and pass it through to the projection pipeline. Store as `MOON_LOCAL_TIMEZONE` env var or derive from system clock.

---

### 3.4 Compaction Traceability — Summary Anchors *(Lilac §1)*

Compaction summaries must act as functional "wormholes" back to raw history, not static text blocks.

- **Change**: Replace `compaction_notes: Vec<String>` with `compaction_anchors: Vec<CompactionAnchor>`, storing the `message_id` associated with each compaction event.
- **Benefit**: If a recall search hit occurs on a summary, the system can instantly calculate the exact message offset in the source JSONL to begin deep-traversal reconstruction.
- **Affected files**: `distill.rs` (extraction), `archive.rs` (rendering `## Compaction Notes` with anchor IDs).

---

### 3.5 Side-Effect Prioritization — Actionable Signals *(Lilac §2)*

Differentiate passive observation (reading) from active modification (writing/executing) to improve recall ranking.

- **Change**: Add `ToolPriority` enum (`High | Normal`) to `ProjectionEntry`. Classify tools at extraction time:
  - **High Priority**: `write_to_file`, `exec` (git/rm/mv), `edit`, `gateway` (config.patch)
  - **Normal Priority**: `read_file`, `web_search`, `ls`
- **Benefit**: Boosts "Modification Events" in recall ranking. A query like *"When did we change the config?"* will favor write-tool entries over read-tool entries.
- **Affected files**: `distill.rs` (priority assignment), `recall.rs` (priority-weighted ranking).

---

### 3.6 Contextual Stitching — Thread Coupling *(Lilac §3)*

Preserve cause-and-effect of tool usage by coupling `toolUse` + `toolResult` as single transactions.

- **Change**: In the `## Tool Activity` section, group `assistant:toolUse` and `tool:toolResult` entries as single "Transactions" instead of separate timeline events. The `## Timeline` table remains flat and chronological.
- **Benefit**: Reduces vector embedding fragmentation — each transaction captures both the *intent* (the command) and the *outcome* (the result) in a single high-signal block.
- **Affected files**: `distill.rs` (coupling logic via `coupled_result` field), `archive.rs` (transaction rendering).

---

### 3.7 Multi-Format Timestamp Injection *(Lilac §4)*

Expose more "surface area" for vague temporal queries by injecting natural language timestamps.

- **Change**: Periodically inject human-readable temporal markers into the projection body, such as `[Saturday Morning]`, `[Early in session]`, `[2 hours into session]`.
- **Injection points**: Session start/end, every ~15–30 minutes of session time, and at compaction boundaries.
- **Benefit**: Improves recall for vague temporal queries (e.g., *"What did we do last Saturday morning?"*) which vector models handle better than raw ISO strings.
- **Affected files**: `archive.rs` (`render_projection_markdown_v2` inserts temporal markers).

### 3.3 Backward Compatibility

| Concern | Mitigation |
|---|---|
| Existing v1 projections | `recall.rs` snippet parser already skips frontmatter; new sections are additive. `moon_archive_projection: 2` distinguishes versions. |
| QMD indexing | QMD indexes `**/*.md` — the new format is still markdown. Vector search quality *improves* because the text is now cleaner and better structured. |
| `moon-distill` | Distillers consume `archive_text` from projections. The new format provides richer input. Existing distill prompts work unchanged. |
| `moon-index --backfill` | Add a `--reproject` flag to regenerate v2 projections for existing v1 archives. |

---

## 4. Implementation Phases

### Phase 1: Projection Data Model (Core)
> **Files**: `distill.rs`, `archive.rs`

- [ ] Define `ProjectionData`, `ProjectionEntry`, `CompactionAnchor`, and `ToolPriority` structs
- [ ] Implement `extract_projection_data` (refactor from `load_archive_excerpt`)
- [ ] Implement JSON unescape pre-pass in `clean_candidate_text`
- [ ] Extract timestamps from JSONL message entries
- [ ] Extract tool names from `toolUse`/`toolResult` entries
- [ ] Implement `extract_keywords` function
- [ ] Implement `infer_topics` function (heuristic mode for local distiller)
- [ ] Implement compaction traceability — map `compaction_notes` to origin `message_id` *(Lilac §1)*
- [ ] Implement side-effect priority classification for tool entries *(Lilac §2)*
- [ ] Implement contextual stitching — couple `toolUse` + `toolResult` as transactions *(Lilac §3)*
- [ ] Implement `render_projection_markdown_v2` with all new sections
- [ ] Add natural language timestamp injection at session/compaction boundaries *(Lilac §4)*

### Phase 2: Recall Improvements
> **Files**: `recall.rs`, `snapshot.rs`

- [ ] Add timezone detection at snapshot time
- [ ] Add timezone-aware query pre-processing in `recall`
- [ ] Update `snippet_from_archive` for v2 format
- [ ] Add priority-weighted ranking in `recall` — boost High-priority tool entries *(Lilac §2)*
- [ ] Add `--reproject` flag to `moon-index` for backfilling v2 projections

### Phase 3: Testing & Validation
> **Files**: `tests/`

- [ ] Add unit tests for `extract_projection_data` with sample JSONL
- [ ] Add unit tests for JSON unescape, keyword extraction, topic inference
- [ ] Add integration test: full pipeline from JSONL → v2 projection → recall hit
- [ ] Run `cargo test` to verify no regressions
- [ ] Manual validation: run `moon-snapshot` + `moon-index` on a real session, inspect output

---

## 5. Verification Plan

### Automated Tests
```bash
# Run all existing + new tests
cargo test

# Specific new test targets (after implementation)
cargo test projection_data
cargo test unescape_json
cargo test keyword_extraction
cargo test v2_projection_format
```

### Manual Verification
1. Run `cargo run -- moon-snapshot` on a recent session
2. Inspect the generated `archives/raw/*.md` — verify it has v2 format with all sections
3. Run `cargo run -- moon-index --name history` to re-index
4. Run `cargo run -- moon-recall --name history --query "05:39 AEDT"` — should now return a hit via temporal matching
5. Run `cargo run -- moon-recall --name history --query "run_command cargo build"` — should return hits with tool activity context

---

## 6. Summary of Key Improvements

| Dimension | Before (v1) | After (v2) |
|---|---|---|
| **Timestamps** | Only in YAML `created_at_epoch_secs` (single value) | Per-message UTC + local time, range in frontmatter + natural language markers *(Lilac §4)* |
| **Structure** | Flat `- [role] text` bullet list | Sections: Timeline, Conversations, Tool Activity (with coupled transactions *(Lilac §3)*), Decisions |
| **Tool results** | Capped at 220 chars, JSON blobs rejected entirely | 1024-char cap, JSON unescaped to readable text |
| **Tool ranking** | All tools treated equally | Side-effect priority: write/exec tools ranked above read tools *(Lilac §2)* |
| **Keywords** | None | Auto-extracted, stored in frontmatter + dedicated section |
| **Topics** | None | Inferred from keywords, stored in frontmatter |
| **Timezone** | Not supported | Local timezone stored, queries auto-converted |
| **Compaction** | Not tracked | Traceable anchors with origin `message_id` for deep reconstruction *(Lilac §1)* |
| **Searchability** | Vector-only (semantic) | Hybrid: vector + temporal + keyword + tool-name + priority-weighted |

---

*This MIP directly addresses all three failure causes identified in [moon_recall_failure_report_0539.md](file:///C:/Users/czhu6/gh/MOON/moon_recall_failure_report_0539.md): temporal alignment (§3.2 snapshot.rs, recall.rs + §3.7 NL timestamps), projection signal loss (§3.1 new format, §3.2 relaxed limits + §3.5 priority ranking + §3.6 contextual stitching), and escaped JSON noise (§3.2 unescape pre-pass). Compaction traceability (§3.4) further ensures no information is permanently lost behind summary boundaries.*
